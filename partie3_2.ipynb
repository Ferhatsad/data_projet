{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd16b60a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filename          0\n",
       "url             796\n",
       "description     796\n",
       "type              0\n",
       "filepath          0\n",
       "scraped           0\n",
       "old_filename    796\n",
       "old_filepath      0\n",
       "text_image        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('mon_data.csv')\n",
    "df.dropna(subset=['text_image'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6843679",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df.iloc[:,[-1,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aac4d843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = stopwords.words('english')\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(str(w).lower().strip())\n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "    w = re.sub(r\"([?.!,Â¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    w = re.sub(r\"[^a-zA-Z?.!]+\", \" \", w)\n",
    "    w = re.sub(r'\\b\\w{0,2}\\b', '', w)\n",
    "\n",
    "    # remove stopword\n",
    "    mots = word_tokenize(w.strip())\n",
    "    mots = [mot for mot in mots if mot not in stop_words]\n",
    "    return ' '.join(mots).strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bcc6f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sadoun\\AppData\\Local\\Temp\\ipykernel_9208\\4051206825.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.text_image = df.text_image.apply(lambda x :preprocess_sentence(x))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_image</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>facture logo joanna binet coubertin paris fact...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>joanna binet coubertin paris facture facture c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>facture mon entreprise nom societe adresse pos...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>joanna binet coubertin paris facture cendrillo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>payer ligne facture sfideli . date creation da...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text_image  type\n",
       "0  facture logo joanna binet coubertin paris fact...     0\n",
       "1  joanna binet coubertin paris facture facture c...     0\n",
       "2  facture mon entreprise nom societe adresse pos...     0\n",
       "3  joanna binet coubertin paris facture cendrillo...     0\n",
       "4  payer ligne facture sfideli . date creation da...     0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text_image = df.text_image.apply(lambda x :preprocess_sentence(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29a02899",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_text_train,X_text_test, y_train, y_test=train_test_split(data.text_image,data.type,test_size=0.2,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fd940ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  tensorflow as tf\n",
    "tokenizer=tf.keras.preprocessing.text.Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(X_text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4a8eb827",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=tokenizer.texts_to_sequences(X_text_train)\n",
    "X_test=tokenizer.texts_to_sequences(X_text_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cc1d5904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7900554",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=100, padding='post', truncating='post')\n",
    "X_test=tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=100, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8f3f4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_9 (Embedding)     (None, None, 200)         2000000   \n",
      "                                                                 \n",
      " global_average_pooling1d_9   (None, 200)              0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 256)               51456     \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 23)                5911      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,057,367\n",
      "Trainable params: 2,057,367\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, GlobalAveragePooling1D, Dropout\n",
    "model=Sequential()\n",
    "model.add(Embedding(10000, 200))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(units = 256, activation = \"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units = 23, activation = \"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3add1c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ccf3eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40/40 [==============================] - 2s 26ms/step - loss: 2.9407 - accuracy: 0.2524 - val_loss: 2.6512 - val_accuracy: 0.2611\n",
      "Epoch 2/30\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 2.5071 - accuracy: 0.3538 - val_loss: 2.3051 - val_accuracy: 0.3631\n",
      "Epoch 3/30\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 2.1058 - accuracy: 0.4010 - val_loss: 2.0653 - val_accuracy: 0.3854\n",
      "Epoch 4/30\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 1.8551 - accuracy: 0.4513 - val_loss: 1.9042 - val_accuracy: 0.4363\n",
      "Epoch 5/30\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 1.6658 - accuracy: 0.5136 - val_loss: 1.7719 - val_accuracy: 0.4904\n",
      "Epoch 6/30\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 1.4855 - accuracy: 0.5887 - val_loss: 1.6790 - val_accuracy: 0.4936\n",
      "Epoch 7/30\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 1.3604 - accuracy: 0.6078 - val_loss: 1.5997 - val_accuracy: 0.5350\n",
      "Epoch 8/30\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 1.2355 - accuracy: 0.6518 - val_loss: 1.5239 - val_accuracy: 0.5541\n",
      "Epoch 9/30\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 1.1267 - accuracy: 0.6949 - val_loss: 1.4723 - val_accuracy: 0.5605\n",
      "Epoch 10/30\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 1.0196 - accuracy: 0.7276 - val_loss: 1.4425 - val_accuracy: 0.5541\n",
      "Epoch 11/30\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 0.9401 - accuracy: 0.7564 - val_loss: 1.4201 - val_accuracy: 0.5637\n",
      "Epoch 12/30\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 0.8504 - accuracy: 0.7915 - val_loss: 1.3537 - val_accuracy: 0.6083\n",
      "Epoch 13/30\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 0.7739 - accuracy: 0.8147 - val_loss: 1.3623 - val_accuracy: 0.5955\n",
      "Epoch 14/30\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.7307 - accuracy: 0.8227 - val_loss: 1.3042 - val_accuracy: 0.6178\n",
      "Epoch 15/30\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 0.6648 - accuracy: 0.8387 - val_loss: 1.2786 - val_accuracy: 0.6465\n",
      "Epoch 16/30\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 0.6185 - accuracy: 0.8522 - val_loss: 1.2795 - val_accuracy: 0.6592\n",
      "Epoch 17/30\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.5780 - accuracy: 0.8610 - val_loss: 1.2428 - val_accuracy: 0.6783\n",
      "Epoch 18/30\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 0.5343 - accuracy: 0.8698 - val_loss: 1.2274 - val_accuracy: 0.6656\n",
      "Epoch 19/30\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.5269 - accuracy: 0.8722 - val_loss: 1.2296 - val_accuracy: 0.6752\n",
      "Epoch 20/30\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.5079 - accuracy: 0.8666 - val_loss: 1.2431 - val_accuracy: 0.6529\n",
      "Epoch 21/30\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.4771 - accuracy: 0.8866 - val_loss: 1.2171 - val_accuracy: 0.6624\n",
      "Epoch 22/30\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.4472 - accuracy: 0.8938 - val_loss: 1.2200 - val_accuracy: 0.6783\n",
      "Epoch 23/30\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.4480 - accuracy: 0.8874 - val_loss: 1.2117 - val_accuracy: 0.6783\n",
      "Epoch 24/30\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 0.4371 - accuracy: 0.8898 - val_loss: 1.2461 - val_accuracy: 0.6497\n",
      "Epoch 25/30\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.4263 - accuracy: 0.8874 - val_loss: 1.2174 - val_accuracy: 0.7102\n",
      "Epoch 26/30\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 0.4011 - accuracy: 0.8938 - val_loss: 1.2202 - val_accuracy: 0.6847\n",
      "Epoch 27/30\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 0.3915 - accuracy: 0.9002 - val_loss: 1.2377 - val_accuracy: 0.6529\n",
      "Epoch 28/30\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.3886 - accuracy: 0.8986 - val_loss: 1.2238 - val_accuracy: 0.6911\n",
      "Epoch 29/30\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.3741 - accuracy: 0.8994 - val_loss: 1.2324 - val_accuracy: 0.6752\n",
      "Epoch 30/30\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.3708 - accuracy: 0.9042 - val_loss: 1.2388 - val_accuracy: 0.6879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2639b7f1760>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "model.fit(X_train,y_train,epochs = 30, batch_size = 32,validation_data = [X_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43763ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6813 - accuracy: 0.0223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6812517642974854, 0.02229299396276474]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
